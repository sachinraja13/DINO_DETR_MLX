[09/21 21:48:58.679]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 21:48:58.679]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 21:48:58.679]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 21:49:38.210]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 21:49:38.210]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 21:49:38.210]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 21:54:40.406]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 21:54:40.406]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 21:54:40.406]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 21:54:59.331]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 21:54:59.331]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 21:54:59.332]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 21:55:25.783]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 21:55:25.783]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 21:55:25.784]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 21:56:10.045]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 21:56:10.045]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 21:56:10.045]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 21:56:34.700]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 21:56:34.700]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 21:56:34.700]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 21:57:43.343]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 21:57:43.344]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 21:57:43.345]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 21:57:43.362]: number of params:48886779
[09/21 21:57:43.363]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/21 22:05:36.708]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:05:36.709]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:05:36.709]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:06:32.020]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:06:32.020]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:06:32.020]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:07:38.929]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:07:38.929]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:07:38.929]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:09:16.682]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:09:16.682]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:09:16.682]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:09:36.777]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:09:36.778]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:09:36.778]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:10:05.875]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:10:05.876]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:10:05.876]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:10:55.366]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:10:55.366]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:10:55.367]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:11:16.044]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:11:16.045]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:11:16.045]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:12:08.777]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:12:08.777]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:12:08.777]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:16:40.767]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:16:40.767]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:16:40.767]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:17:50.317]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:17:50.317]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:17:50.318]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:18:14.105]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:18:14.105]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:18:14.105]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:18:54.093]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:18:54.094]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:18:54.094]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:19:56.123]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:19:56.123]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:19:56.123]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:20:10.060]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:20:10.060]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:20:10.061]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:21:25.447]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:21:25.447]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:21:25.447]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:22:16.320]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:22:16.320]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:22:16.320]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:43:01.150]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:43:01.150]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:43:01.150]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:43:01.172]: number of params:48886779
[09/21 22:43:01.173]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/21 22:43:36.354]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:43:36.356]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:43:36.357]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:44:22.161]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:44:22.161]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:44:22.161]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:44:22.185]: number of params:48886779
[09/21 22:44:22.186]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/21 22:52:41.726]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:52:41.726]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:52:41.726]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:53:21.487]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:53:21.487]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:53:21.487]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:53:57.252]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:53:57.253]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:53:57.253]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:56:33.435]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:56:33.435]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:56:33.436]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:58:27.289]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:58:27.290]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:58:27.290]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:59:08.778]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/21 22:59:08.778]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/21 22:59:08.778]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/21 22:59:08.946]: number of params:48886779
[09/21 22:59:08.947]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 08:33:12.687]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 08:33:12.688]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 08:33:12.688]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 08:33:35.620]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 08:33:35.620]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 08:33:35.620]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 08:34:32.089]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 08:34:32.090]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 08:34:32.090]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 08:34:32.222]: number of params:48886779
[09/22 08:34:32.223]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 08:38:07.455]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 08:38:07.455]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 08:38:07.455]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 08:38:07.596]: number of params:48886779
[09/22 08:38:07.597]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 08:42:29.126]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 08:42:29.126]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 08:42:29.126]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 08:42:29.267]: number of params:48886779
[09/22 08:42:29.268]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 09:24:47.975]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 09:24:47.975]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 09:24:47.976]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 09:25:03.866]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 09:25:03.867]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 09:25:03.867]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 09:25:04.024]: number of params:48886779
[09/22 09:25:04.025]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 09:38:08.595]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 09:38:08.595]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 09:38:08.595]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 09:38:08.746]: number of params:48886779
[09/22 09:38:08.747]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 09:38:49.747]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path tmp --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 09:38:49.747]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 09:38:49.747]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='tmp', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 09:38:49.918]: number of params:48886779
[09/22 09:38:49.919]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 09:58:34.439]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 09:58:34.439]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 09:58:34.439]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 09:58:34.899]: number of params:48886779
[09/22 09:58:34.899]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:00:07.075]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:00:07.075]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:00:07.075]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:00:07.218]: number of params:48886779
[09/22 10:00:07.219]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:01:05.544]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:01:05.545]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:01:05.545]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:01:05.680]: number of params:48886779
[09/22 10:01:05.681]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:01:31.136]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:01:31.136]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:01:31.136]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:01:31.268]: number of params:48886779
[09/22 10:01:31.269]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:04:12.311]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:04:12.311]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:04:12.311]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:04:12.516]: number of params:48886779
[09/22 10:04:12.517]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:05:59.110]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:05:59.110]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:05:59.110]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:05:59.249]: number of params:48886779
[09/22 10:05:59.250]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:09:54.826]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:09:54.827]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:09:54.827]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:09:54.966]: number of params:48886779
[09/22 10:09:54.967]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:11:39.880]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:11:39.881]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:11:39.881]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:11:40.025]: number of params:48886779
[09/22 10:11:40.026]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:14:13.240]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:14:13.240]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:14:13.240]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:14:13.388]: number of params:48886779
[09/22 10:14:13.389]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:19:26.674]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:19:26.675]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:19:26.675]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:19:26.814]: number of params:48886779
[09/22 10:19:26.815]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:21:43.398]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:21:43.398]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:21:43.398]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:21:43.538]: number of params:48886779
[09/22 10:21:43.538]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:26:28.754]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:26:28.754]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:26:28.754]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:26:28.893]: number of params:48886779
[09/22 10:26:28.894]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:28:53.989]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:28:53.990]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:28:53.990]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:28:54.134]: number of params:48886779
[09/22 10:28:54.139]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:30:50.345]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:30:50.345]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:30:50.345]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:30:50.475]: number of params:48886779
[09/22 10:30:50.476]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:32:25.197]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:32:25.197]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:32:25.197]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:32:25.343]: number of params:48886779
[09/22 10:32:25.344]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:33:34.411]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:33:34.411]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:33:34.411]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:33:34.595]: number of params:48886779
[09/22 10:33:34.596]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:34:22.337]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:34:22.337]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:34:22.337]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:34:22.501]: number of params:48886779
[09/22 10:34:22.503]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:35:50.615]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:35:50.615]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:35:50.615]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:35:50.784]: number of params:48886779
[09/22 10:35:50.786]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:36:53.302]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:36:53.302]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:36:53.302]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:36:53.450]: number of params:48886779
[09/22 10:36:53.452]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:37:42.731]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:37:42.731]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:37:42.731]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:37:42.939]: number of params:48886779
[09/22 10:37:42.940]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:39:09.599]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:39:09.599]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:39:09.599]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:39:34.517]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:39:34.517]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:39:34.517]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:39:34.671]: number of params:48886779
[09/22 10:39:34.672]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:41:11.101]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:41:11.101]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:41:11.101]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:41:11.270]: number of params:48886779
[09/22 10:41:11.271]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:42:02.252]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:42:02.253]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:42:02.253]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:42:02.427]: number of params:48886779
[09/22 10:42:02.428]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:42:46.266]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:42:46.267]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:42:46.267]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:42:46.493]: number of params:48886779
[09/22 10:42:46.494]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:43:27.317]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:43:27.317]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:43:27.317]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:43:27.475]: number of params:48886779
[09/22 10:43:27.478]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:44:19.096]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:44:19.097]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:44:19.097]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:44:19.264]: number of params:48886779
[09/22 10:44:19.265]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:45:42.771]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:45:42.771]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:45:42.772]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:45:42.947]: number of params:48886779
[09/22 10:45:42.948]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:46:42.488]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:46:42.488]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:46:42.488]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:46:42.626]: number of params:48886779
[09/22 10:46:42.629]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:47:18.837]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:47:18.837]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:47:18.837]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:47:18.971]: number of params:48886779
[09/22 10:47:18.972]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:48:48.836]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:48:48.836]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:48:48.836]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:48:49.002]: number of params:48886779
[09/22 10:48:49.003]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:50:15.301]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:50:15.301]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:50:15.301]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:50:15.446]: number of params:48886779
[09/22 10:50:15.447]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:51:57.227]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:51:57.227]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:51:57.228]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:51:57.355]: number of params:48886779
[09/22 10:51:57.356]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:53:15.880]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:53:15.880]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:53:15.880]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:53:16.018]: number of params:48886779
[09/22 10:53:16.019]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:54:13.704]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:54:13.705]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:54:13.705]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:54:13.838]: number of params:48886779
[09/22 10:54:13.839]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:54:54.950]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:54:54.950]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:54:54.950]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:54:55.084]: number of params:48886779
[09/22 10:54:55.085]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:55:57.173]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:55:57.173]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:55:57.173]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:55:57.316]: number of params:48886779
[09/22 10:55:57.317]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:57:41.780]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:57:41.781]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:57:41.781]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:57:41.945]: number of params:48886779
[09/22 10:57:41.946]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 10:58:55.843]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 10:58:55.843]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 10:58:55.843]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 10:58:56.006]: number of params:48886779
[09/22 10:58:56.007]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:01:32.288]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:01:32.288]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:01:32.288]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:01:32.459]: number of params:48886779
[09/22 11:01:32.460]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:11:14.272]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:11:14.272]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:11:14.272]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:11:14.409]: number of params:48886779
[09/22 11:11:14.410]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:12:34.695]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:12:34.695]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:12:34.695]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:12:34.884]: number of params:48886779
[09/22 11:12:34.885]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:14:01.399]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:14:01.399]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:14:01.399]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:14:01.579]: number of params:48886779
[09/22 11:14:01.580]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:15:19.462]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:15:19.462]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:15:19.463]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:15:19.610]: number of params:48886779
[09/22 11:15:19.611]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:16:50.567]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:16:50.567]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:16:50.567]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:16:50.746]: number of params:48886779
[09/22 11:16:50.747]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:17:31.277]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:17:31.277]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:17:31.277]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:17:31.443]: number of params:48886779
[09/22 11:17:31.444]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:18:30.238]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:18:30.238]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:18:30.238]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:18:30.407]: number of params:48886779
[09/22 11:18:30.408]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:19:40.590]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:19:40.590]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:19:40.590]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:19:40.734]: number of params:48886779
[09/22 11:19:40.734]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:20:47.900]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:20:47.900]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:20:47.900]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:20:48.030]: number of params:48886779
[09/22 11:20:48.031]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:23:05.545]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:23:05.546]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:23:05.546]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:23:05.694]: number of params:48886779
[09/22 11:23:05.695]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:27:29.689]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:27:29.689]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:27:29.689]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:27:29.844]: number of params:48886779
[09/22 11:27:29.844]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:33:15.233]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:33:15.233]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:33:15.233]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:33:15.385]: number of params:48886779
[09/22 11:33:15.386]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:34:45.047]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:34:45.047]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:34:45.047]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:34:45.206]: number of params:48886779
[09/22 11:34:45.207]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:36:15.067]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:36:15.068]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:36:15.068]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:36:15.191]: number of params:48886779
[09/22 11:36:15.192]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:37:02.575]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:37:02.576]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:37:02.576]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:37:02.706]: number of params:48886779
[09/22 11:37:02.707]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:38:18.445]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:38:18.445]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:38:18.445]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:38:18.606]: number of params:48886779
[09/22 11:38:18.607]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:43:21.342]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:43:21.342]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:43:21.342]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:43:21.482]: number of params:48886779
[09/22 11:43:21.483]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 11:50:09.263]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 11:50:09.263]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 11:50:09.264]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='no', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 11:50:09.390]: number of params:48668076
[09/22 11:50:09.391]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.refpoint_embed.weight": 3600,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 12:32:22.360]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 12:32:22.360]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 12:32:22.360]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 12:32:22.517]: number of params:48886779
[09/22 12:32:22.518]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
[09/22 12:35:18.411]: Command: main.py --output_dir logs/DINO/R50-MS4 -c config/DINO/DINO_4scale.py --coco_path /Users/sachinraja/Datasets/coco_2014_dataset --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/22 12:35:18.411]: Full config saved to logs/DINO/R50-MS4/config_args_all.json
[09/22 12:35:18.411]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/Users/sachinraja/Datasets/coco_2014_dataset', remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4', note='', device='metal', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', batch_size=1, weight_decay=0.0001, epochs=30, lr_drop_steps=50000, lr_drop_epochs=5, lr_drop_factor=0.5, save_checkpoint_interval=1, clip_max_norm=0.1, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperature=20, return_interm_indices=[1, 2, 3, 4], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='no', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=False, dn_number=0, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0, use_ema=False)

[09/22 12:35:18.585]: number of params:48668076
[09/22 12:35:18.585]: params:
{
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.params.encoder_layer.self_attn.attention_weights.bias": 128,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.value_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.weight": 65536,
  "transformer.encoder.params.encoder_layer.self_attn.output_proj.bias": 256,
  "transformer.encoder.params.encoder_layer.norm1.weight": 256,
  "transformer.encoder.params.encoder_layer.norm1.bias": 256,
  "transformer.encoder.params.encoder_layer.linear1.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear1.bias": 2048,
  "transformer.encoder.params.encoder_layer.linear2.weight": 524288,
  "transformer.encoder.params.encoder_layer.linear2.bias": 256,
  "transformer.encoder.params.encoder_layer.norm2.weight": 256,
  "transformer.encoder.params.encoder_layer.norm2.bias": 256,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.params.decoder_layer.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.cross_attn.output_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm1.weight": 256,
  "transformer.decoder.params.decoder_layer.norm1.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.query_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.key_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.value_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.weight": 65536,
  "transformer.decoder.params.decoder_layer.self_attn.out_proj.bias": 256,
  "transformer.decoder.params.decoder_layer.norm2.weight": 256,
  "transformer.decoder.params.decoder_layer.norm2.bias": 256,
  "transformer.decoder.params.decoder_layer.linear1.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear1.bias": 2048,
  "transformer.decoder.params.decoder_layer.linear2.weight": 524288,
  "transformer.decoder.params.decoder_layer.linear2.bias": 256,
  "transformer.decoder.params.decoder_layer.norm3.weight": 256,
  "transformer.decoder.params.decoder_layer.norm3.bias": 256,
  "transformer.decoder.params.norm.weight": 256,
  "transformer.decoder.params.norm.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.query_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.query_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.key_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.key_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.decoder.class_embed.1.weight": 23296,
  "transformer.decoder.class_embed.1.bias": 91,
  "transformer.decoder.class_embed.2.weight": 23296,
  "transformer.decoder.class_embed.2.bias": 91,
  "transformer.decoder.class_embed.3.weight": 23296,
  "transformer.decoder.class_embed.3.bias": 91,
  "transformer.decoder.class_embed.4.weight": 23296,
  "transformer.decoder.class_embed.4.bias": 91,
  "transformer.decoder.class_embed.5.weight": 23296,
  "transformer.decoder.class_embed.5.bias": 91,
  "transformer.level_embed": 1024,
  "transformer.tgt_embed.weight": 230400,
  "transformer.refpoint_embed.weight": 3600,
  "label_enc.weight": 23552,
  "input_proj.0.layers.0.weight": 65536,
  "input_proj.0.layers.0.bias": 256,
  "input_proj.0.layers.1.bias": 256,
  "input_proj.0.layers.1.weight": 256,
  "input_proj.1.layers.0.weight": 131072,
  "input_proj.1.layers.0.bias": 256,
  "input_proj.1.layers.1.bias": 256,
  "input_proj.1.layers.1.weight": 256,
  "input_proj.2.layers.0.weight": 262144,
  "input_proj.2.layers.0.bias": 256,
  "input_proj.2.layers.1.bias": 256,
  "input_proj.2.layers.1.weight": 256,
  "input_proj.3.layers.0.weight": 524288,
  "input_proj.3.layers.0.bias": 256,
  "input_proj.3.layers.1.bias": 256,
  "input_proj.3.layers.1.weight": 256,
  "backbone.layers.0.body.conv1.weight": 9408,
  "backbone.layers.0.body.bn1.weight": 64,
  "backbone.layers.0.body.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv1.weight": 4096,
  "backbone.layers.0.body.layer1.layers.0.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.0.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.0.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.0.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.0.weight": 16384,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.weight": 256,
  "backbone.layers.0.body.layer1.layers.0.downsample.layers.1.bias": 256,
  "backbone.layers.0.body.layer1.layers.1.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.1.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.1.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.1.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.1.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.1.bn3.bias": 256,
  "backbone.layers.0.body.layer1.layers.2.conv1.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn1.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn1.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv2.weight": 36864,
  "backbone.layers.0.body.layer1.layers.2.bn2.weight": 64,
  "backbone.layers.0.body.layer1.layers.2.bn2.bias": 64,
  "backbone.layers.0.body.layer1.layers.2.conv3.weight": 16384,
  "backbone.layers.0.body.layer1.layers.2.bn3.weight": 256,
  "backbone.layers.0.body.layer1.layers.2.bn3.bias": 256,
  "backbone.layers.0.body.layer2.layers.0.conv1.weight": 32768,
  "backbone.layers.0.body.layer2.layers.0.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.0.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.0.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.0.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.0.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.0.weight": 131072,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.weight": 512,
  "backbone.layers.0.body.layer2.layers.0.downsample.layers.1.bias": 512,
  "backbone.layers.0.body.layer2.layers.1.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.1.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.1.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.1.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.1.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.1.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.2.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.2.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.2.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.2.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.2.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.2.bn3.bias": 512,
  "backbone.layers.0.body.layer2.layers.3.conv1.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn1.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn1.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv2.weight": 147456,
  "backbone.layers.0.body.layer2.layers.3.bn2.weight": 128,
  "backbone.layers.0.body.layer2.layers.3.bn2.bias": 128,
  "backbone.layers.0.body.layer2.layers.3.conv3.weight": 65536,
  "backbone.layers.0.body.layer2.layers.3.bn3.weight": 512,
  "backbone.layers.0.body.layer2.layers.3.bn3.bias": 512,
  "backbone.layers.0.body.layer3.layers.0.conv1.weight": 131072,
  "backbone.layers.0.body.layer3.layers.0.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.0.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.0.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.0.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.0.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.0.weight": 524288,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.weight": 1024,
  "backbone.layers.0.body.layer3.layers.0.downsample.layers.1.bias": 1024,
  "backbone.layers.0.body.layer3.layers.1.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.1.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.1.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.1.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.1.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.1.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.2.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.2.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.2.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.2.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.2.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.2.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.3.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.3.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.3.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.3.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.3.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.3.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.4.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.4.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.4.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.4.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.4.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.4.bn3.bias": 1024,
  "backbone.layers.0.body.layer3.layers.5.conv1.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn1.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn1.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv2.weight": 589824,
  "backbone.layers.0.body.layer3.layers.5.bn2.weight": 256,
  "backbone.layers.0.body.layer3.layers.5.bn2.bias": 256,
  "backbone.layers.0.body.layer3.layers.5.conv3.weight": 262144,
  "backbone.layers.0.body.layer3.layers.5.bn3.weight": 1024,
  "backbone.layers.0.body.layer3.layers.5.bn3.bias": 1024,
  "backbone.layers.0.body.layer4.layers.0.conv1.weight": 524288,
  "backbone.layers.0.body.layer4.layers.0.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.0.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.0.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.0.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.0.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.0.weight": 2097152,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.weight": 2048,
  "backbone.layers.0.body.layer4.layers.0.downsample.layers.1.bias": 2048,
  "backbone.layers.0.body.layer4.layers.1.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.1.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.1.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.1.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.1.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.1.bn3.bias": 2048,
  "backbone.layers.0.body.layer4.layers.2.conv1.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn1.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn1.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv2.weight": 2359296,
  "backbone.layers.0.body.layer4.layers.2.bn2.weight": 512,
  "backbone.layers.0.body.layer4.layers.2.bn2.bias": 512,
  "backbone.layers.0.body.layer4.layers.2.conv3.weight": 1048576,
  "backbone.layers.0.body.layer4.layers.2.bn3.weight": 2048,
  "backbone.layers.0.body.layer4.layers.2.bn3.bias": 2048,
  "backbone.layers.0.body.fc.weight": 2048000,
  "backbone.layers.0.body.fc.bias": 1000,
  "bbox_embed.0.layers.0.weight": 65536,
  "bbox_embed.0.layers.0.bias": 256,
  "bbox_embed.0.layers.1.weight": 65536,
  "bbox_embed.0.layers.1.bias": 256,
  "bbox_embed.0.layers.2.weight": 1024,
  "bbox_embed.0.layers.2.bias": 4,
  "bbox_embed.1.layers.0.weight": 65536,
  "bbox_embed.1.layers.0.bias": 256,
  "bbox_embed.1.layers.1.weight": 65536,
  "bbox_embed.1.layers.1.bias": 256,
  "bbox_embed.1.layers.2.weight": 1024,
  "bbox_embed.1.layers.2.bias": 4,
  "bbox_embed.2.layers.0.weight": 65536,
  "bbox_embed.2.layers.0.bias": 256,
  "bbox_embed.2.layers.1.weight": 65536,
  "bbox_embed.2.layers.1.bias": 256,
  "bbox_embed.2.layers.2.weight": 1024,
  "bbox_embed.2.layers.2.bias": 4,
  "bbox_embed.3.layers.0.weight": 65536,
  "bbox_embed.3.layers.0.bias": 256,
  "bbox_embed.3.layers.1.weight": 65536,
  "bbox_embed.3.layers.1.bias": 256,
  "bbox_embed.3.layers.2.weight": 1024,
  "bbox_embed.3.layers.2.bias": 4,
  "bbox_embed.4.layers.0.weight": 65536,
  "bbox_embed.4.layers.0.bias": 256,
  "bbox_embed.4.layers.1.weight": 65536,
  "bbox_embed.4.layers.1.bias": 256,
  "bbox_embed.4.layers.2.weight": 1024,
  "bbox_embed.4.layers.2.bias": 4,
  "bbox_embed.5.layers.0.weight": 65536,
  "bbox_embed.5.layers.0.bias": 256,
  "bbox_embed.5.layers.1.weight": 65536,
  "bbox_embed.5.layers.1.bias": 256,
  "bbox_embed.5.layers.2.weight": 1024,
  "bbox_embed.5.layers.2.bias": 4,
  "class_embed.0.weight": 23296,
  "class_embed.0.bias": 91,
  "class_embed.1.weight": 23296,
  "class_embed.1.bias": 91,
  "class_embed.2.weight": 23296,
  "class_embed.2.bias": 91,
  "class_embed.3.weight": 23296,
  "class_embed.3.bias": 91,
  "class_embed.4.weight": 23296,
  "class_embed.4.bias": 91,
  "class_embed.5.weight": 23296,
  "class_embed.5.bias": 91
}
